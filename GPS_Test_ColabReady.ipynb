{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install exifread opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850836b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Upload image\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded image\n",
    "image = None\n",
    "for fn in uploaded.keys():\n",
    "    image = Image.open(io.BytesIO(uploaded[fn]))\n",
    "    print(f\"Loaded image: {fn}\")\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a04cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install exifread opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b99bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Upload image\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded image\n",
    "image = None\n",
    "for fn in uploaded.keys():\n",
    "    image = Image.open(io.BytesIO(uploaded[fn]))\n",
    "    print(f\"Loaded image: {fn}\")\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "QPhupwKuGoAS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPhupwKuGoAS",
    "outputId": "738f92a6-58ae-4f69-e92c-4f6170008cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.146)\n",
      "Requirement already satisfied: piexif in /usr/local/lib/python3.11/dist-packages (1.1.3)\n",
      "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'libimage-exiftool-perl' instead of 'exiftool'\n",
      "libimage-exiftool-perl is already the newest version (12.40+dfsg-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages in one Colab cell\n",
    "!pip install ultralytics piexif geopy\n",
    "!apt-get install -y exiftool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "i9h7QAF9GqFA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9h7QAF9GqFA",
    "outputId": "5a897ff7-2c3b-4df4-bb38-51eb34aeade6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "_Ge8aoZaGs0E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ge8aoZaGs0E",
    "outputId": "f5db2f0a-1d1e-40a8-d865-e07f42684cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['samenvatting v4 stof scheikunde 16-17.pdf',\n",
       " 'Discrete Mathematics and Its Applications.pdf',\n",
       " 'Computer_Organization_and_Design_By_David_Patterson_5th_ed.pdf',\n",
       " 'The 19th century Orthodox response to assimilation and progress.gdoc',\n",
       " 'KAVV Jodendom.gdoc',\n",
       " 'Work.pdf',\n",
       " 'Work.gsheet',\n",
       " 'Ecuador.gsheet',\n",
       " 'SSO Assignment1.gdoc',\n",
       " 'FDSv2.gdoc',\n",
       " 'SSO Assingment2.gsheet',\n",
       " 'Assingment 3 SSO.gsheet',\n",
       " 'DS Project Text.gdoc',\n",
       " 'Colab Notebooks',\n",
       " 'feather-in-focus',\n",
       " 'Societal Complexity and Designing with Data',\n",
       " 'Group3-midterm.pdf',\n",
       " 'Full_table_all_matches_for_dupes_DEC.csv',\n",
       " 'Untitled document.gdoc',\n",
       " 'Untitled spreadsheet.gsheet',\n",
       " 'Japan Plan.pdf',\n",
       " 'Brief papa.gdoc',\n",
       " 'Japan Plan.gdoc',\n",
       " 'Motivatie brief woo.gdoc',\n",
       " 'Motivatie brief woo.pdf',\n",
       " 'Elephants',\n",
       " 'Brief papa.pdf',\n",
       " 'AnimalData',\n",
       " 'PhD referal Letter.gdoc',\n",
       " 'PhD referal Letter.docx',\n",
       " 'datasets',\n",
       " 'Personal statement .gdoc',\n",
       " 'Plymouth Personal Statement Letter.gdoc',\n",
       " 'PHD Applications answers.gdoc',\n",
       " 'Google AI Studio',\n",
       " 'PhD interview prep Plymouth.gdoc',\n",
       " 'NetGain Questions.gdoc',\n",
       " 'NetGain PP.gslides',\n",
       " 'PhD Plymouth Interview 2.gdoc',\n",
       " 'PhD interview prep AI Intervene shy sharks.gdoc',\n",
       " 'PhD interview prep AI Intervene Depth .gdoc',\n",
       " 'NetGain PP.pdf',\n",
       " 'Leverhum PP.gslides',\n",
       " 'ExaGeo.gslides',\n",
       " 'ExaGeo .gdoc',\n",
       " 'MacBook Back-Up 2025']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List files in the root of Google Drive\n",
    "os.listdir('/content/drive/My Drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-LtqJV-kGs6l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LtqJV-kGs6l",
    "outputId": "7d6d429c-7154-4d6f-fcae-852677afbb0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/datasets/GPS\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/datasets/GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "JuBSVo2PGz-h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuBSVo2PGz-h",
    "outputId": "262cc25b-5cfb-45f3-eb43-94940619506e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best_xl.pt      'GPS Test.ipynb'                 \u001b[0m\u001b[01;34mProcessed_Distances_Output\u001b[0m/\n",
      " \u001b[01;34mDetections\u001b[0m/      \u001b[01;34mImages\u001b[0m/                         \u001b[01;34mProcessed_Images_Output\u001b[0m/\n",
      " DJI_0395-1.SRT   \u001b[01;34mProcessed_Coordinates_Output\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2bcd3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df2bcd3f",
    "outputId": "0f0dc7bf-c200-4752-80c9-16f3e170c277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO, SAM\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a30a26",
   "metadata": {
    "id": "16a30a26"
   },
   "outputs": [],
   "source": [
    "def Find_Elephants(image_path):\n",
    "  # Load the YOLOv11 model\n",
    "  model = YOLO(\"best_xl.pt\")  # Replace with your model path\n",
    "\n",
    "  # Input image path\n",
    "  results = model.predict(source=image_path, conf=0.6)\n",
    "\n",
    "  # Prepare output folder\n",
    "  output_dir = \"Detections\"\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  # Load image\n",
    "  im1 = cv2.imread(image_path)\n",
    "  height, width, _ = im1.shape\n",
    "\n",
    "  # Get base filename (without extension)\n",
    "  base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "  # Prepare output data and counter\n",
    "  yolo_format_data = []\n",
    "  num_objects = 0  # Counter for detected objects\n",
    "\n",
    "  # Process each detected box\n",
    "  for box in results[0].boxes:\n",
    "      num_objects += 1\n",
    "\n",
    "      cls = int(box.cls[0])\n",
    "      conf = float(box.conf[0])\n",
    "      x1, y1, x2, y2 = map(float, box.xyxy[0])\n",
    "\n",
    "      # Draw bounding box and label on image\n",
    "      cv2.rectangle(im1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "      cv2.putText(im1, f'Class: {cls}, Conf: {conf:.2f}', (int(x1), int(y1) - 10),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "      # Normalize xmin, ymin, xmax, ymax\n",
    "      xmin_norm = x1 / width\n",
    "      ymin_norm = y1 / height\n",
    "      xmax_norm = x2 / width\n",
    "      ymax_norm = y2 / height\n",
    "\n",
    "      # Append to YOLO format list with normalized coordinates\n",
    "      yolo_format_data.append(f\"{cls} {conf:.6f} {xmin_norm:.6f} {ymin_norm:.6f} {xmax_norm:.6f} {ymax_norm:.6f}\")\n",
    "\n",
    "  # Save annotated image and txt file to Detections folder\n",
    "  output_image_path = os.path.join(output_dir, f\"{base_name}.jpg\")\n",
    "  output_txt_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "\n",
    "  cv2.imwrite(output_image_path, im1)\n",
    "  with open(output_txt_path, 'w') as f:\n",
    "      f.write(\"\\n\".join(yolo_format_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exyZPgMh-5cs",
   "metadata": {
    "id": "exyZPgMh-5cs"
   },
   "outputs": [],
   "source": [
    "def extract_exiftool_metadata(image_path):\n",
    "    # Run exiftool and get JSON output\n",
    "    result = subprocess.run(\n",
    "        ['exiftool', '-j', image_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"exiftool failed: {result.stderr}\")\n",
    "\n",
    "    metadata = json.loads(result.stdout)[0]\n",
    "    return metadata\n",
    "\n",
    "def extract_exif_metadata_partial(image_path):\n",
    "    metadata = extract_exiftool_metadata(image_path)\n",
    "\n",
    "    # Relative Altitude (usually in meters)\n",
    "    rel_alt = float(metadata.get('RelativeAltitude', 0))\n",
    "\n",
    "    # Gimbal Pitch (try 'GimbalPitchDegree' or fallback to 'GimbalPitch')\n",
    "    pitch_deg = float(metadata.get('GimbalPitchDegree', metadata.get('GimbalPitch', -90)))\n",
    "\n",
    "    # DateTimeOriginal (format \"YYYY:MM:DD HH:MM:SS\")\n",
    "    datetime_str = metadata.get('DateTimeOriginal')\n",
    "    if not datetime_str:\n",
    "        raise ValueError(\"No DateTimeOriginal tag found in image EXIF metadata.\")\n",
    "    time_str = datetime_str.split(' ')[1]\n",
    "\n",
    "    # FocalLength (usually in mm)\n",
    "    focal_length_str = metadata.get('FocalLength', '0')\n",
    "    focal_length_mm = float(focal_length_str.split(' ')[0])  # take only the numeric part before any space\n",
    "\n",
    "    # Sensor width and height fallback defaults (in mm)\n",
    "    sensor_width_mm = 17.3\n",
    "    sensor_height_mm = 13.0\n",
    "\n",
    "    # Image dimensions\n",
    "    img_width = int(metadata.get('ImageWidth', 0))\n",
    "    img_height = int(metadata.get('ImageHeight', 0))\n",
    "\n",
    "    # GPS Coordinates\n",
    "    gps_lat = metadata.get('GPSLatitude')\n",
    "    gps_lon = metadata.get('GPSLongitude')\n",
    "\n",
    "    def dms_to_decimal(dms_str):\n",
    "        \"\"\"\n",
    "        Converts a DMS (Degrees, Minutes, Seconds) string to decimal degrees.\n",
    "        Example input: '24 deg 13\\' 36.24\" S'\n",
    "        \"\"\"\n",
    "        pattern = r'(\\d+)[^\\d]+(\\d+)[^\\d]+([\\d.]+)[^\\d]+([NSEW])'\n",
    "        match = re.match(pattern, dms_str.strip())\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid DMS format: {dms_str}\")\n",
    "        degrees, minutes, seconds, direction = match.groups()\n",
    "        decimal = float(degrees) + float(minutes)/60 + float(seconds)/3600\n",
    "        if direction in ['S', 'W']:\n",
    "            decimal = -decimal\n",
    "        return decimal\n",
    "\n",
    "    latitude = dms_to_decimal(gps_lat) if gps_lat else None\n",
    "    longitude = dms_to_decimal(gps_lon) if gps_lon else None\n",
    "\n",
    "    return rel_alt, pitch_deg, time_str, focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height, latitude, longitude\n",
    "\n",
    "def extract_metadata(image_path):\n",
    "    rel_alt, pitch_deg, _, focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height, lat, lon = extract_exif_metadata_partial(image_path)\n",
    "    return lat, lon, rel_alt, pitch_deg, focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height\n",
    "\n",
    "def get_camera_intrinsics(focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height):\n",
    "    fx = img_width * focal_length_mm / sensor_width_mm\n",
    "    fy = img_height * focal_length_mm / sensor_height_mm\n",
    "    cx = img_width / 2\n",
    "    cy = img_height / 2\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0, 0, 1]])\n",
    "    return K\n",
    "\n",
    "def get_rotation_matrix(pitch_deg, yaw_deg=0.0, roll_deg=0.0):\n",
    "    pitch = math.radians(pitch_deg)\n",
    "    yaw = math.radians(yaw_deg)\n",
    "    roll = math.radians(roll_deg)\n",
    "\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, math.cos(roll), -math.sin(roll)],\n",
    "                    [0, math.sin(roll), math.cos(roll)]])\n",
    "\n",
    "    R_y = np.array([[math.cos(pitch), 0, math.sin(pitch)],\n",
    "                    [0, 1, 0],\n",
    "                    [-math.sin(pitch), 0, math.cos(pitch)]])\n",
    "\n",
    "    R_z = np.array([[math.cos(yaw), -math.sin(yaw), 0],\n",
    "                    [math.sin(yaw), math.cos(yaw), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "    R = R_z @ R_y @ R_x\n",
    "    return R\n",
    "\n",
    "def enu_to_wgs84(x, y, origin_lat, origin_lon):\n",
    "    transformer_local = Transformer.from_crs(\"epsg:4979\", \"epsg:4978\", always_xy=True)\n",
    "    transformer = Transformer.from_crs(\"epsg:4978\", \"epsg:4326\", always_xy=True)\n",
    "    z = 0\n",
    "    ecef_x0, ecef_y0, ecef_z0 = transformer_local.transform(origin_lon, origin_lat, z)\n",
    "    ecef_x = ecef_x0 + x\n",
    "    ecef_y = ecef_y0 + y\n",
    "    ecef_z = ecef_z0\n",
    "    lon, lat, _ = transformer.transform(ecef_x, ecef_y, ecef_z)\n",
    "    return lat, lon\n",
    "\n",
    "def image_point_to_gps(u, v, K, R, cam_height, origin_lat, origin_lon):\n",
    "    pixel = np.array([u, v, 1])\n",
    "    ray_cam = np.linalg.inv(K) @ pixel\n",
    "    ray_world = R @ ray_cam\n",
    "\n",
    "    scale = -cam_height / ray_world[2]\n",
    "    ground_point = ray_world * scale\n",
    "\n",
    "    enu_x, enu_y = ground_point[0], ground_point[1]\n",
    "\n",
    "    lat, lon = enu_to_wgs84(enu_x, enu_y, origin_lat, origin_lon)\n",
    "    return lat, lon\n",
    "\n",
    "def run_pipeline(image_path, bounding_boxes):\n",
    "    lat, lon, alt, pitch_deg, focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height = extract_metadata(image_path)\n",
    "\n",
    "    K = get_camera_intrinsics(focal_length_mm, sensor_width_mm, sensor_height_mm, img_width, img_height)\n",
    "    R = get_rotation_matrix(pitch_deg)\n",
    "\n",
    "    gps_results = []\n",
    "    for i, box in enumerate(bounding_boxes, start=1):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        center_u = (x_min + x_max) / 2 * img_width  # convert relative to pixels if needed\n",
    "        center_v = (y_min + y_max) / 2 * img_height\n",
    "\n",
    "        gps_lat, gps_lon = image_point_to_gps(center_u, center_v, K, R, alt, lat, lon)\n",
    "        gps_results.append((i, (center_u, center_v), (gps_lat, gps_lon)))\n",
    "\n",
    "    return gps_results\n",
    "\n",
    "def plot_results(image_path, results):\n",
    "    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img)\n",
    "    for obj_id, (u, v), (lat, lon) in results:\n",
    "        plt.plot(u, v, 'ro')\n",
    "        plt.text(u + 5, v, f\"ID {obj_id}: {lat:.5f}, {lon:.5f}\", color='yellow', fontsize=8)\n",
    "    plt.title(\"Bounding Box Centers with GPS Coordinates\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "VfYppMFFUWSM",
   "metadata": {
    "id": "VfYppMFFUWSM"
   },
   "outputs": [],
   "source": [
    "def save_results_to_csv(results, csv_path):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['ObjectID', 'Latitude', 'Longitude'])\n",
    "        for obj_id, (u, v), (lat, lon) in results:\n",
    "            writer.writerow([obj_id, f\"{lat:.6f}\", f\"{lon:.6f}\"])\n",
    "\n",
    "\n",
    "def save_image_with_ids(image_path, results, output_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Overlay only object IDs at the center points\n",
    "    for obj_id, (u, v), _ in results:\n",
    "        pos = (int(u), int(v))\n",
    "        cv2.putText(img, f\"ID {obj_id}\", pos, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1.5, color=(0, 255, 255), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Saved image with IDs overlayed to {output_path}\")\n",
    "\n",
    "import os\n",
    "\n",
    "def get_base_name(image_path):\n",
    "    return os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def save_distances_csv(results, csv_path):\n",
    "    # results: list of tuples (id, (u,v), (lat, lon))\n",
    "    # Calculate pairwise distances in meters\n",
    "    ids = [r[0] for r in results]\n",
    "    coords = [(r[2][0], r[2][1]) for r in results]  # (lat, lon)\n",
    "\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = ['ObjectID_1', 'ObjectID_2', 'Distance_meters']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            for j in range(i+1, len(results)):\n",
    "                dist = geodesic(coords[i], coords[j]).meters\n",
    "                writer.writerow([ids[i], ids[j], f\"{dist:.2f}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ao35HcXDXz7U",
   "metadata": {
    "id": "ao35HcXDXz7U"
   },
   "outputs": [],
   "source": [
    "def load_bounding_boxes_from_txt(txt_path, conf_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Loads bounding boxes from a text file with lines formatted as:\n",
    "    cls conf xmin_norm ymin_norm xmax_norm ymax_norm\n",
    "\n",
    "    Args:\n",
    "        txt_path (str): Path to the txt file.\n",
    "        conf_threshold (float): Minimum confidence threshold to keep a bbox.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: (xmin_norm, ymin_norm, xmax_norm, ymax_norm)\n",
    "    \"\"\"\n",
    "    bounding_boxes = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 6:\n",
    "                # Ignore malformed lines\n",
    "                continue\n",
    "\n",
    "            cls, conf, xmin, ymin, xmax, ymax = parts\n",
    "            conf = float(conf)\n",
    "            if conf < conf_threshold:\n",
    "                continue\n",
    "\n",
    "            xmin = float(xmin)\n",
    "            ymin = float(ymin)\n",
    "            xmax = float(xmax)\n",
    "            ymax = float(ymax)\n",
    "\n",
    "            bounding_boxes.append((xmin, ymin, xmax, ymax))\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "BuW9HY02fTKT",
   "metadata": {
    "id": "BuW9HY02fTKT"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_file(file_path, timeout=30):\n",
    "    \"\"\"Waits for a file to exist up to a timeout (in seconds).\"\"\"\n",
    "    start_time = time.time()\n",
    "    while not os.path.exists(file_path):\n",
    "        time.sleep(0.3)\n",
    "        if time.time() - start_time > timeout:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "iGMLaN_VJJLJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGMLaN_VJJLJ",
    "outputId": "327be78e-5d22-4d9c-83a0-7620a21a8ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: Images/DJI_0396.JPG\n",
      "\n",
      "image 1/1 /content/drive/MyDrive/datasets/GPS/Images/DJI_0396.JPG: 480x640 4 Elephants, 3526.2ms\n",
      "Speed: 12.7ms preprocess, 3526.2ms inference, 28.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# --- Define shared paths ---\n",
    "images_folder = \"Images\"\n",
    "\n",
    "# Step 1: Run detection on all images\n",
    "image_files = list(Path(images_folder).glob(\"*.JPG\"))\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = str(image_file)\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "    Find_Elephants(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "npwObiJuKxRC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npwObiJuKxRC",
    "outputId": "b1dfe725-8b9e-4744-f3cb-82bcf2317460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: Images/DJI_0396.JPG\n",
      "Saved image with IDs overlayed to Processed_Images_Output/DJI_0396_output_with_ids.jpg\n",
      "Saved:\n",
      "- Processed_Coordinates_Output/DJI_0396_object_gps_coordinates.csv\n",
      "- Processed_Images_Output/DJI_0396_output_with_ids.jpg\n",
      "- Processed_Distances_Output/DJI_0396_object_distances.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output folders if they don't exist\n",
    "output_folder_Distances = \"Processed_Distances_Output\"\n",
    "output_folder_Coordinates = \"Processed_Coordinates_Output\"\n",
    "output_folder_Images = \"Processed_Images_Output\"\n",
    "os.makedirs(output_folder_Distances, exist_ok=True)\n",
    "os.makedirs(output_folder_Coordinates, exist_ok=True)\n",
    "os.makedirs(output_folder_Images, exist_ok=True)\n",
    "\n",
    "images_folder = \"Images\"\n",
    "\n",
    "# Iterate over images in the Detections folder\n",
    "for image_file in Path(images_folder).glob(\"*.JPG\"):\n",
    "    image_path = str(image_file)\n",
    "    base_name = image_file.stem\n",
    "    txt_file = os.path.join(\"Detections\", f\"{base_name}.txt\")\n",
    "\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "\n",
    "    # Step 3: Load detections\n",
    "    boxes = load_bounding_boxes_from_txt(txt_file, conf_threshold=0.6)\n",
    "\n",
    "    # Step 4: Run full pipeline\n",
    "    results = run_pipeline(image_path, boxes)\n",
    "\n",
    "    # Step 5: Define output paths\n",
    "    csv_output_path = os.path.join(output_folder_Coordinates, f\"{base_name}_object_gps_coordinates.csv\")\n",
    "    image_output_path = os.path.join(output_folder_Images, f\"{base_name}_output_with_ids.jpg\")\n",
    "    distance_csv_path = os.path.join(output_folder_Distances, f\"{base_name}_object_distances.csv\")\n",
    "\n",
    "    # Step 6: Save outputs\n",
    "    save_results_to_csv(results, csv_output_path)\n",
    "    save_image_with_ids(image_path, results, image_output_path)\n",
    "    save_distances_csv(results, distance_csv_path)\n",
    "\n",
    "    print(f\"Saved:\\n- {csv_output_path}\\n- {image_output_path}\\n- {distance_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yK1tuWAE8tae",
   "metadata": {
    "id": "yK1tuWAE8tae"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
